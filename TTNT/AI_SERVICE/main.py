from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import os
import re
from dotenv import load_dotenv
import google.generativeai as genai

from rag_service import (
    retrieve_context,
    format_rag_context,
    get_products_from_backend
)

load_dotenv()

# ================== APP ==================
app = FastAPI(
    title="Phonify AI Shopping Assistant",
    description="AI Chatbox + Shopping Assistant (Compare, Combo, Summary)",
    version="3.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://localhost:8000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ================== CONFIG ==================
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-flash-latest")
BACKEND_URL = os.getenv("BACKEND_URL", "http://localhost:8000")
AI_SERVICE_PORT = int(os.getenv("AI_SERVICE_PORT", "8001"))

if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# ================== PROMPTS ==================
SYSTEM_PROMPT = """B·∫°n l√† tr·ª£ l√Ω AI mua s·∫Øm chuy√™n nghi·ªáp c·ªßa c·ª≠a h√†ng Phonify.
- Ch·ªâ s·ª≠ d·ª•ng d·ªØ li·ªáu c√≥ trong CONTEXT (database) ƒë·ªÉ tr·∫£ l·ªùi.
- Tuy·ªát ƒë·ªëi kh√¥ng t·ª± b·ªãa ƒë·∫∑t gi√° c·∫£, t·ªìn kho hay th√¥ng s·ªë k·ªπ thu·∫≠t.
- N·∫øu kh√¥ng th·∫•y s·∫£n ph·∫©m trong d·ªØ li·ªáu, h√£y xin l·ªói v√† b√°o l√† ch∆∞a c·∫≠p nh·∫≠t th√¥ng tin.
- Lu√¥n s·ª≠ d·ª•ng icon (emojis) ƒë·ªÉ c√¢u tr·∫£ l·ªùi sinh ƒë·ªông v√† d·ªÖ ƒë·ªçc.
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, l·ªãch s·ª±, th√¢n thi·ªán.
"""

COMPARE_PROMPT = """
So s√°nh chi ti·∫øt c√°c s·∫£n ph·∫©m sau cho kh√°ch h√†ng.
H√£y ph√¢n t√≠ch s·ª± kh√°c bi·ªát v·ªÅ: Gi√°, C·∫•u h√¨nh n·ªïi b·∫≠t, v√† ∆∞u th·∫ø ri√™ng c·ªßa t·ª´ng m√°y.
Cu·ªëi c√πng h√£y ƒë∆∞a ra l·ªùi khuy√™n n√™n ch·ªçn m√°y n√†o cho nhu c·∫ßu g√¨.

D·ªØ li·ªáu s·∫£n ph·∫©m:
{products}
"""

# ƒê√É C·∫¨P NH·∫¨T: Prompt m√¥ t·∫£ nhanh ch·∫•t l∆∞·ª£ng h∆°n
SUMMARY_PROMPT = """
H√£y vi·∫øt m·ªôt b·∫£n M√î T·∫¢ NHANH ƒë·∫ßy ƒë·ªß v√† h·∫•p d·∫´n cho s·∫£n ph·∫©m n√†y:
- üåü ƒêi·ªÉm n·ªïi b·∫≠t nh·∫•t (Top Features)
- üí∞ ƒê√°nh gi√° v·ªÅ m·ª©c gi√° hi·ªán t·∫°i
- ‚úÖ ∆Øu ƒëi·ªÉm & ‚ùå Nh∆∞·ª£c ƒëi·ªÉm (n·∫øu c√≥ t·ª´ ƒë√°nh gi√°)
- üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Ph√π h·ª£p v·ªõi ƒë·ªëi t∆∞·ª£ng kh√°ch h√†ng n√†o?

S·∫£n ph·∫©m:
{product}

ƒê√°nh gi√° th·ª±c t·∫ø t·ª´ kh√°ch:
{reviews}
"""

COMBO_PROMPT = """
Kh√°ch h√†ng ƒëang quan t√¢m s·∫£n ph·∫©m n√†y: {product}

D·ª±a tr√™n s·∫£n ph·∫©m n√†y, h√£y g·ª£i √Ω m·ªôt Combo ho√†n h·∫£o g·ªìm c√°c ph·ª• ki·ªán ƒëi k√®m.
H√£y gi·∫£i th√≠ch t·∫°i sao Combo n√†y l·∫°i c·∫ßn thi·∫øt v√† gi√∫p n√¢ng cao tr·∫£i nghi·ªám s·ª≠ d·ª•ng.
"""

# ================== MODELS ==================
class Message(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    message: str
    conversationHistory: Optional[List[Message]] = []
    backendUrl: Optional[str] = None

class ChatResponse(BaseModel):
    success: bool
    message: str
    data: dict

# ================== HELPERS ==================
def detect_intent(message: str) -> str:
    msg = message.lower()
    # Th√™m "m√¥ t·∫£", "chi ti·∫øt" v√†o nh·∫≠n di·ªán SUMMARY
    if any(k in msg for k in ["so s√°nh", "kh√°c nhau", "n√™n mua c√°i n√†o", "h∆°n k√©m"]):
        return "COMPARE"
    if any(k in msg for k in ["combo", "mua k√®m", "ph·ª• ki·ªán", "set"]):
        return "COMBO"
    if any(k in msg for k in ["t√≥m t·∫Øt", "review", "ƒë√°nh gi√°", "ƒë√°ng mua", "m√¥ t·∫£", "chi ti·∫øt", "th√¥ng s·ªë"]):
        return "SUMMARY"
    return "NORMAL"

def normalize_products(raw_products: list) -> list:
    products = []
    for p in raw_products:
        products.append({
            "productId": p.get("productId"),
            "name": p.get("name"),
            "price": p.get("price", 0),
            "category": p.get("category", "N/A"),
            "description": p.get("description", ""),
            "stockQuantity": p.get("stockQuantity", 0),
            "thumbnail": p.get("thumbnail") or p.get("image")
        })
    return products

def build_gemini_model():
    # S·ª≠ d·ª•ng c√°ch khai b√°o an to√†n cho c√°c phi√™n b·∫£n th∆∞ vi·ªán kh√°c nhau
    return genai.GenerativeModel(GEMINI_MODEL)

# ================== ENDPOINT ==================
@app.post("/api/v1/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    if not request.message.strip():
        raise HTTPException(status_code=400, detail="Message r·ªóng")

    backend_url = request.backendUrl or BACKEND_URL
    intent = detect_intent(request.message)

    # L·∫•y d·ªØ li·ªáu t·ª´ RAG (Database)
    rag_context = await retrieve_context(request.message, backend_url)
    raw_products = rag_context.get("products", [])
    products = normalize_products(raw_products)
    reviews = rag_context.get("reviews", [])
    
    # ƒê·ªãnh d·∫°ng context ƒë·ªÉ ƒë∆∞a v√†o AI
    formatted_context = format_rag_context(rag_context)

    model = build_gemini_model()
    chat_session = model.start_chat(history=[])

    # ================== COMPARE ==================
    if intent == "COMPARE" and len(products) >= 2:
        prompt = f"{formatted_context}\n\n{COMPARE_PROMPT.format(products=products[:3])}"
        response = chat_session.send_message(prompt)

        return ChatResponse(
            success=True,
            message="So s√°nh s·∫£n ph·∫©m",
            data={
                "type": "compare",
                "response": response.text.strip(),
                "products": products[:3]
            }
        )

    # ================== SUMMARY (M√¥ t·∫£ nhanh) ==================
    if intent == "SUMMARY" and products:
        prompt = f"{formatted_context}\n\n{SUMMARY_PROMPT.format(product=products[0], reviews=reviews[:3])}"
        response = chat_session.send_message(prompt)

        return ChatResponse(
            success=True,
            message="T√≥m t·∫Øt s·∫£n ph·∫©m",
            data={
                "type": "summary",
                "response": response.text.strip(),
                "product": products[0]
            }
        )

    # ================== COMBO ==================
    if intent == "COMBO" and products:
        accessories = await get_products_from_backend(backend_url, search_term="ph·ª• ki·ªán")
        combo_products = normalize_products(accessories[:3])

        prompt = f"{formatted_context}\n\n{COMBO_PROMPT.format(product=products[0])}"
        response = chat_session.send_message(prompt)

        return ChatResponse(
            success=True,
            message="G·ª£i √Ω combo",
            data={
                "type": "combo",
                "response": response.text.strip(),
                "product": products[0],
                "comboProducts": combo_products
            }
        )

    # ================== NORMAL (H·ªèi ƒë√°p th√¥ng th∆∞·ªùng) ==================
    prompt = f"{formatted_context}\n\nC√¢u h·ªèi c·ªßa kh√°ch: {request.message}\n\nH√£y tr·∫£ l·ªùi d·ª±a tr√™n d·ªØ li·ªáu th·ª±c t·∫ø ph√≠a tr√™n."
    response = chat_session.send_message(prompt)

    return ChatResponse(
        success=True,
        message="Tr√≤ chuy·ªán AI",
        data={
            "type": "text",
            "response": response.text.strip(),
            "products": products[:3] if products else []
        }
    )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=AI_SERVICE_PORT)